PyCon 2015 - lvh :
"Node" = machine (à vérifier)

Un système distribué est un ensemble d'au moins 2 machines connectées par un réseau.
Contraintes fondamentales :  Vitesse de l'information / déficience des composants

CAP theorem : Consistency, Availability, Partition tolerance (choisir 2)
C -> linearizability = Toutes les opérations s'effectuent "instantanément"
A -> serializability = Il existe une exécution séquentielle avec le même résultat
P -> résistance aux déficiences

Strong serializability = serializability + linearizability
Il faut faire des "trade-offs" pour choisir enter C et A. Exemple SQL : on peut choisir le degré de consistance des données

Les écritures peuvent ne pas être répliquées, réorganisées...

On classifie le degré de consistance des données (Theoretical consistency models).

Twisted : 1 Thread mais E/S en parallèle


Temps :
Global clock model : horloge unique -> on peut comparer les timestamps
Local clock model : plusieurs horloges à peu près à l'heure -> on ne peut plus comparer les timestamps
Lamport clock : horloge "logique", chaque machine à sa version du compteur, chaque opération augmente le compteur de 1, à chaque échange, chaque machine retient la valeur la plus grande du compteur.
Vector clock : version plus évoluée de la Lamport clock, chaque machine enregistre chacune des horloges logiques -> détection des conflits

On besoin de l'heure pour établir une timeline, les machines n'ont pas besoin de l'heure "humaine"

Solutions :
- Queues
- Consensus protocols algorithms (établir un consensus sur les données entre toutes las machines) :
    - ZAB
    - Paxos
    - Raft
  -> Recette : verrous ; barrières ; Partitionnages d'ensemble..

CRDTs (Conflict-free Replicated Data Types)
  -> On décrit ce que l'on souhaite lors de la résolution de conflit (merge function par exemple)

Commutative RDT : CmRDT (somme d'entiers) -> l'ordre n'est pas important, mais chaque opération doit être réalisée seulement 1 fois pour que le résultat final soit le bon
Convergent RDT : CvRDT (concaténation d'ensemble d'entier) -> on réalise toutes les opérations dans n'importe quel ordre et on fusionne les résultats, on arrivera au résultat final correct
CvRDT le plus souvent
*
-> Voir page de bloc sur les CRDTs (théorie des ensembles / relations d'ordres)
*

Pour MUTE, il faut considérer les CRDTs pour les séquences.

-------------------------------------------------------------------
Syncing data across user devices for distributed collaboration - Martin Kleppman :

Google Docs = cloud software / SaaS / web apps -> Le document et la majorité de l'application sont stockés sur le serveur

Local first software -> rapproché le document de l'utilisateur (stockage local)
7 Ideaux :
- Fast -> (optimistic UI pour les cloud software) avec le stockage local, pas besoin d'attendre une réponse du serveur
- Multi-device -> Il faut synchroniser les données
- Work offline -> La synchronisation peut se faire une fois que la connexion internet est rétablie, ou alors on peut utiliser d'autres moyens pour communiquer (bluetooth, peer-to-peer...)
- Seamless collaboration -> Google Docs style (collaboration en temps réel si la connexion fonctionne) / Git style (pull/push) -> gestion des conflits (fusion automatique)
- Long-term preservation -> Internet archive garde des sites et applications des années 1980 mais pas certaines applications web de 2010
- Security and privacy -> cryptage end to end (là où le serveur décrypte les données pour des cloud software)
- User control

eventual consistency
  - eventual delivery -> eventually, every op seen by every node (asynchronous)
  - convergence -> si plusieurs utilisateurs ont vus les mêmes opérations, alors ils doivent être dans le même état
  - ne pas perdre de données

Algorithmes de convergence : Operational transformation (Google Docs) / CRDTs (permet la collaboration sans aucun serveur -> pas de supposition sur la topologie du réseau)

Les CRDTs ont étés prouvés corrects à l'aide du software Isabelle (la consistance à été prouvée avec des suppositions qui sont toujours vérifiées)
La seule situation de conflit non résolu, c'est la mise à jour concourante de la même propriété d'un même objet par plusieurs utilisateurs.

Fonctionnement du CRDT pour une application quelconque :
  * L'utilisateur ajoute des donnnées *
  - On crée un "pointeur" commun à toutes les machines pour désigner l'opération/l'objet ajouté
    -> ce pointeur servira à créer les opérations qui affecte cet objet
    -> Ce pointeur doit être construit de manière unique et doit permettre d'identifier l'utilisateur
  - Le paramètre "overwrite", va permettre de changer une valeur en supprimant l'ancienne valeur
  - Si 2 opérations concourante porte sur le même objet (même référence/ID) mais qu'aucune des 2 n'a l'attribut "overwrite", c'est une situation de conflit non résolu

Cas du traitement de texte collaboratif :
  - Chaque ajout de caractère est considéré comme une opération et possède son propre ID.
  - Le nouveau caractère aura le numéro MAX+1 (Lamport timestamp) et un identifiant pour connaître la machine qui crée cette édition.
  - Pour savoir où insérer le caractère, on se sert du poitneur du caractère juste avant ("insert 'x' after 3a as 7c")
  - Ici, il ne peut pas y avoir de conflit non résolu, en cas d'insertion concourante au même endroit, on gère le problème à l'aide de l'algorithme RGA.
Algorithme RGA : lors de l'insertion du caractère, l'insertion se fait après tout élément de la liste avec un id plus grand (à partir de la position d'ajout prévue par l'opération).
  - Lors de la suppression d'un caractère, le pointeur existe toujours est permet encore de situer la position d'insertion des nouveaux caractères.

-------------------------------------------------------------------
Designing Data-Intensive Applications - Martin Kleppman (Chapitres 1, 5 et 8) :

Data-Systems -> Databases, caches, search indexes, streeam processing, batch processing
The boundaries between teh categories are becoming blured
One tool can't proccess all data on it's own, we need to break down the work into pieces that can be performed by a single tool.
Although, you need to keep theses tools coherents to provide consistent results (data system design)

3 concerns that are important in most software systemes: Reliability, Scalability, Maintainabilitiy.
Reliability :
  - “continuing to work correctly even when things go wrong” - The things that can go wrong are called faults
  - It only makes sense to talk about tolerating certain types of faults
  - Prevent faults from causing failures
  - Hardware faults ->
    * Add redundancy (dual power supplies, redundant componenent) as the number of nodes grows, this become less efficient
    * "Hence there is a move toward systems that can tolerate the loss of entire machines, by
    using software fault-tolerance techniques in preference or in addition to hardware
    redundancy"
  - Software errors -> cause many more system failures than uncorrelated hardware faults
  - Human errors -> leading cause of outages

Scalability :
  - system’s ability to cope with increased load ("reliability in the future")
  - You need parameters to define load
  - Describing Performance ->
    * Batch processing : throughput (number of record processed/second)
    * Online systsems : response time -> distribution of values that you can measure.
  - This makes the median a good metric if you want to know how long users typically have to wait (we also use percentiles)
  - tail latency amplification : when doing parallel requests, the user will have to wait for the longest to be completed
  - Coping with load :
    -> scaling up (moving to a more powerful machine)/ scaling out (sitributing the load across several machines)
    -> "elastic system can be useful if load is highly unpredictable" (add computing resiyrce when they detect a laod increase)
    -> So far, you wanted to keep your database on a singlez node as long as possible but it may change (due to better/easier distributed systems tools)
    -> an architecture that scales well for a particular application is built around assumptions

Maintainabilitiy :
  - 3 design principles : Operability, Simplicity, Evolvability
    -> To keep the system operable, you need to provide visibility, support, documentaition and avoid dependancies
    -> Abstraction is really import to keep the software simple
    -> Evolvability (=agility)


Replication :
Several reasons :
  -> Keep data close to the user to reduce latency
  -> To increase fault tolerance (system may continue working even when a part fails)
  -> To scale horizontaly (increase read throughput)
We will assume that your dataset is so small that each machine can hold a copy of the entire dataset

3 algorithms to handle changes : single-leader, multi-leaders, leaderless replication
Single-leader :
  - Synchronous Versus Asynchronous Replication :
    -> With Synchronous replication, the follower is ensured to have a conistent up-to-date copy
    -> With Asynchronous, the system is much faster and there isn't anymore the case where a single unavailable synchronous replica blocks all writes
  - Follower failure: Catch-up recovery / Leader failure: Failover
  - Implementation of Replciation logs : Statement-based replication / WAL shipping / Logical log replication / Trigger-based replciation
  - Leader/follower replciation problem --> small inconsistency while the follower is catching up that can elad to problems :
    -> Reading your own writes : if you try to read your write just after isnertion, you may have the replcia of a follower cathing-up and you'll see a version where your last write doesn't exists yet
    -> User to see things moving backward in time -> Monotonic reads
    -> Violation of causality (distributed databases) -> consistent prefix reads

Multi-leader :
  - Benefits : Performance, tolerance of datacenter outages, tolerance of network problems
    Downside : conflicts, complexity
  - It allows offline operation / collaborative editing
  - Handling write conflicts : conflict avoidance, converging toward a consistent state, automatic resolution
  - The topology of the network affects the way the systems works.

Leaderless replciation :
  - Writing to the database when a node is down : 2 solutions to catch up : read repair and anti-entropy process
  - Quorum condition : w + r > n - If w + r <= n, the read/write retun an error
  - There is limits to quorum consistency (p182)
  - Sloppy quorums and hinted handoff
  - Detecting concurrent writes :
    -> LWW discards concurrent writes
    -> We need to now how to tell that two operatiosn are concurrent : "happens-before" relationship / concurrency
    -> To do that, we use an algorithm that proceed version numbers to figure out these relationships
    -> We call a deletion mark a "tombstone"
    -> With several node, the collection of version numbers from all the replicas is called a version Vector


Chapter 8 : distributed system are :
  - nondeterministic
  - subject to partial failure
  - using unreliable networks, unreliable clocks and nodes that may pause (+ Byzantine faults)

  -> Protocols that enlist help from other nodes and try to get quorum to agree are required to make decisions despite the partials failures that might be caused
  (it is possible to give hard real-time response guarantees and bounded delays in network)
